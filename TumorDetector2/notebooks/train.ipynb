{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train**\n",
    "This notebook is desired to train the Tumor Detector 2.0 with high-level training informations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "from TumorDetector2.utils.metrics import loss_menager,\\\n",
    "                                         apply_threshold,\\\n",
    "                                         DiceCoeficient\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# data handler\n",
    "from TumorDetector2.utils.weights import TrainLogging,\\\n",
    "                                         load_architecture\n",
    "from TumorDetector2.utils.data import load_tfrecord\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# graphs\n",
    "from TumorDetector2.utils.graphs import TrainingGraph\n",
    "\n",
    "# system\n",
    "from tensorflow._api.v2.config import list_physical_devices,\\\n",
    "                                      list_logical_devices,\\\n",
    "                                      set_visible_devices,\\\n",
    "                                      set_logical_device_configuration,\\\n",
    "                                      LogicalDeviceConfiguration\n",
    "from tensorflow import GradientTape\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Checking GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if GPU is available\n",
    "gpus = list_physical_devices(device_type='GPU')\n",
    "if gpus.__len__():\n",
    "    set_visible_devices(devices=gpus[0], device_type='GPU')\n",
    "    # limiting GPU memory\n",
    "    set_logical_device_configuration(\n",
    "        device=gpus[0],\n",
    "        logical_devices=[\n",
    "            LogicalDeviceConfiguration(memory_limit=3584) # limiting to 3.5GB\n",
    "        ]\n",
    "    )\n",
    "    device = list_logical_devices(device_type='GPU')\n",
    "    print('GPU has been detected: ' + str(device))\n",
    "else:\n",
    "    print('No GPU has been detected. The GPU acceleration is not enabled, it is EXTREMELLY recommended to use GPU for training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - data\n",
    "SHUFFLE_DATA = True\n",
    "PREFETCH = 2\n",
    "BATCH = 4\n",
    "\n",
    "# - training\n",
    "MODEL_VERSION = 'v1'\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "EARLY_STOP = 5\n",
    "LOSS_TRANSFORMER = 'real'\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# - metrics\n",
    "LOSS = BinaryCrossentropy()\n",
    "METRIC = DiceCoeficient()\n",
    "OPTIMIZER = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# - graphs\n",
    "GRAPH = TrainingGraph(LOSS, METRIC, EPOCHS, BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Model Configs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = load_architecture(MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load TFRecord File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET, TEST_DATASET, VAL_DATASET = load_tfrecord(BATCH, PREFETCH, SHUFFLE_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "LOSSES = []\n",
    "VAL_LOSSES = []\n",
    "\n",
    "ACCURACIES = []\n",
    "VAL_ACCURACIES = []\n",
    "\n",
    "BEST_LOSS = None\n",
    "BEST_VAL_LOSS = None\n",
    "\n",
    "ACCURACY = None\n",
    "VAL_ACCURACY = None\n",
    "\n",
    "PREVIOUS_VAL_LOSS = None\n",
    "\n",
    "OVERFITTING = 0\n",
    "\n",
    "TOTAL_ITERATIONS = None\n",
    "\n",
    "TRAIN_LOGGING = TrainLogging()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    # training inference\n",
    "    ITER_TRAINING = tqdm(iterable=TRAIN_DATASET, desc=f'EPOCH: {epoch}/{EPOCHS} | Training', total=TOTAL_ITERATIONS)\n",
    "    \n",
    "    mean_loss = 0\n",
    "    mean_accuracy = 0\n",
    "    for iterations, (image, mask, label) in enumerate(ITER_TRAINING):\n",
    "        \n",
    "        with GradientTape() as tape:\n",
    "        \n",
    "            # running inference\n",
    "            predicted = MODEL(image, training=True)\n",
    "            \n",
    "            # calculating loss\n",
    "            loss = loss_menager(\n",
    "                loss=LOSS(mask, predicted),\n",
    "                apply=LOSS_TRANSFORMER\n",
    "            )\n",
    "            \n",
    "            # applying threshold\n",
    "            if THRESHOLD != 0.0 and type(THRESHOLD) == float:\n",
    "                predicted = apply_threshold(predicted, THRESHOLD)\n",
    "            \n",
    "            # calculating accuracy\n",
    "            accuracy = METRIC(mask, predicted)\n",
    "            \n",
    "            # saving results\n",
    "            LOSSES.append(loss)\n",
    "            ACCURACIES.append(accuracy)\n",
    "            mean_loss += loss\n",
    "            mean_accuracy += accuracy\n",
    "            \n",
    "            # gradiant\n",
    "            grads = tape.gradient(target=loss, sources=MODEL.trainable_weights)\n",
    "            OPTIMIZER.apply_gradients(grads_and_vars=zip(grads, MODEL.trainable_weights))\n",
    "    mean_loss /= (iterations + 1) # mean loss of training\n",
    "    mean_accuracy /= (iterations + 1) # mean accuracy of training\n",
    "    \n",
    "    # saving total iterations\n",
    "    if TOTAL_ITERATIONS is None:\n",
    "        TOTAL_ITERATIONS = iterations + 1\n",
    "    \n",
    "    # validating\n",
    "    print('Validating..')\n",
    "    \n",
    "    mean_val_loss = 0\n",
    "    mean_val_accuracy = 0\n",
    "    SAMPLES = []\n",
    "    for iterations, (image, mask, label) in enumerate(VAL_DATASET):\n",
    "        \n",
    "        # running inference\n",
    "        predicted = MODEL(image, training=False)\n",
    "        \n",
    "        # calculating loss\n",
    "        loss = loss_menager(\n",
    "                loss=LOSS(mask, predicted),\n",
    "                apply=LOSS_TRANSFORMER\n",
    "            )\n",
    "\n",
    "        # calculating accuracy\n",
    "        if THRESHOLD != 0.0 and type(THRESHOLD) == float:\n",
    "            accuracy = METRIC(mask, apply_threshold(predicted, THRESHOLD))\n",
    "        else:\n",
    "            accuracy = METRIC(mask, predicted)\n",
    "        \n",
    "        # saving results\n",
    "        VAL_LOSSES.append(loss)\n",
    "        VAL_ACCURACIES.append(accuracy)\n",
    "        mean_val_loss += loss\n",
    "        mean_val_accuracy += accuracy\n",
    "        \n",
    "        # getting random data to visualize\n",
    "        index = np.random.choice(a=np.arange(BATCH), size=1)[0]\n",
    "        try:\n",
    "            image = image[index][:,:,0].numpy() # getting the image channel\n",
    "            predicted = predicted[index][:,:,0].numpy() # getting the predicted segmentation channel\n",
    "            mask = mask[index][:,:,0].numpy() # getting the tumor channel\n",
    "            \n",
    "            # preview results\n",
    "            preview_results = [image, mask]\n",
    "            \n",
    "            # applying thresholds\n",
    "            for threshold in [0.3, 0.5, 0.7]:\n",
    "                \n",
    "                new_predict = predicted.copy()\n",
    "                new_predict[new_predict >= threshold] = 1\n",
    "                new_predict[new_predict < threshold] = 0\n",
    "                \n",
    "                preview_results.append(new_predict)\n",
    "            \n",
    "            # saving validation data\n",
    "            SAMPLES.append(preview_results)\n",
    "        except: pass\n",
    "    SAMPLES = np.array(SAMPLES)\n",
    "        \n",
    "    mean_val_loss /= (iterations + 1) # mean val loss of validation\n",
    "    mean_val_accuracy /= (iterations + 1) # mean val accuracy of validation\n",
    "    \n",
    "    # displaying graph\n",
    "    LOSS_FIG, VAL_GRAPH = GRAPH.plot(\n",
    "        LOSSES,\n",
    "        VAL_LOSSES,\n",
    "        ACCURACIES,\n",
    "        VAL_ACCURACIES,\n",
    "        mean_loss,\n",
    "        mean_val_loss,\n",
    "        mean_accuracy,\n",
    "        mean_val_accuracy,\n",
    "        epoch,\n",
    "        SAMPLES\n",
    "    )\n",
    "    \n",
    "    # saving weights\n",
    "    SAVE = False\n",
    "    if BEST_LOSS is None or (mean_loss < BEST_LOSS and mean_val_loss < BEST_VAL_LOSS):\n",
    "        BEST_LOSS = mean_loss\n",
    "        BEST_VAL_LOSS = mean_val_loss\n",
    "        ACCURACY = mean_accuracy\n",
    "        VAL_ACCURACY = mean_val_accuracy\n",
    "        SAVE = True\n",
    "        \n",
    "    TRAIN_LOGGING.save(\n",
    "        MODEL,\n",
    "        MODEL_VERSION,\n",
    "        BEST_LOSS,\n",
    "        BEST_VAL_LOSS,\n",
    "        ACCURACY,\n",
    "        VAL_ACCURACY,\n",
    "        LOSS.name,\n",
    "        METRIC.name,\n",
    "        OPTIMIZER._name,\n",
    "        epoch,\n",
    "        EPOCHS,\n",
    "        THRESHOLD,\n",
    "        LEARNING_RATE,\n",
    "        BATCH,\n",
    "        LOSS_TRANSFORMER,\n",
    "        LOSS_FIG,\n",
    "        VAL_GRAPH,\n",
    "        SAVE\n",
    "    )\n",
    "    \n",
    "    # early stop\n",
    "    if PREVIOUS_VAL_LOSS is None:\n",
    "        PREVIOUS_VAL_LOSS = mean_val_loss\n",
    "    else:\n",
    "        if mean_val_loss > PREVIOUS_VAL_LOSS:\n",
    "            OVERFITTING += 1\n",
    "        else:\n",
    "            if OVERFITTING > 0:\n",
    "                OVERFITTING -= 1\n",
    "        PREVIOUS_VAL_LOSS = mean_val_loss\n",
    "    if OVERFITTING == EARLY_STOP:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tumor2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a85f04fc2d61e1fef6e97851a3e88513b6d93b5e20faaafa8617ef23e0ce8c96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
